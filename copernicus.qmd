---
title: "Copernicus for Sanctuaries"
format:
  html:
    toc: true
    embed-resources: true
    code-fold: true
    code-tools: true    
editor_options: 
  chunk_output_type: console
---

## Setup for copernicusmarine in R

-   [How to sign up for Copernicus Marine Service? | Copernicus Marine Help Center](https://help.marine.copernicus.eu/en/articles/4220332-how-to-sign-up-for-copernicus-marine-service)

-   [How to download data via the Copernicus Marine Toolbox in R? \| Copernicus Marine Help Center](https://help.marine.copernicus.eu/en/articles/8638253-how-to-download-data-via-the-copernicus-marine-toolbox-in-r#h_c480a903fd): R `reticulate` to Python `copernicusmarine`.

```{r}
#| label: set up python env
# do once: create virtual enviroment and install copernicusmarine Python module
# virtualenv_create(envname = "CopernicusMarine")
# virtualenv_install(envname = "CopernicusMarine", packages = c("copernicusmarine"))
# 
# TODO: check for CopernicusMarine env with copernicusmarine Python module
```

## setup R environment
```{r}
#| label: setup
librarian::shelf(
  dplyr, DT, ggplot2, glue, here, jsonlite, leaflet, mapview, ncdf4, readr, reticulate, 
  sf, stringr, terra, tidyr,
  quiet = T)
options(readr.show_col_types = F)

sanctuaries_geo <- here("data/sanctuaries.geojson")
# copernicusmarine username and password
# user        <- "bbest1"
user        <- "tmurray"
pass_txt    <- "~/My Drive/private/data.marine.copernicus.eu_bbest1-password.txt"
dir_cm      <- here("data/copernicus")
results_csv <- here("data/copernicus.csv")
```

## Sanctuaries

We are extracting Copernicus Marine data from across National Marine Sanctuaries, borrowing polygons from the [noaa-onms/climate-dashboard](https://github.com/noaa-onms/climate-dashboard) (see Github [code](https://noaa-onms.github.io/climate-dashboard/)).

```{r}
#| label: sanctuaries

if (!file.exists(sanctuaries_geo)){
  # source: https://github.com/noaa-onms/climate-dashboard/blob/main/data/sanctuaries.rds
  sanctuaries_rds <- here("../climate-dashboard/data/sanctuaries.rds")
  readRDS(sanctuaries_rds) |> 
    filter(nms != "TBNMS") |> # exclude Great Lakes
    write_sf(sanctuaries_geo, delete_dsn = T)
}

sanctuaries <- read_sf(sanctuaries_geo)
sanctuaries |> 
  st_drop_geometry() |> 
  datatable()
mapView(sanctuaries)
```


```{r}
#| label: cmt
# use virtualenv and reticulate::import copernicusmarine Python module
use_virtualenv(virtualenv = "CopernicusMarine", required = TRUE)
cmt <- import("copernicusmarine")

# login
pass <- readLines(pass_txt)
cmt$login(user, pass) #, skip_if_user_logged_in = T) # py_help(cmt$login)
# writes to ~/.copernicusmarine/.copernicusmarine-credentials
```

## Extract Global Ocean Physics Reanalysis

Product > Dataset > Variable

- Product: [Global Ocean Physics Reanalysis | Copernicus Marine Service](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/description)\
  Product name: Global Ocean Physics Reanalysis\
  Product identifier: `GLOBAL_MULTIYEAR_PHY_001_030`

- Dataset: `cmems_mod_glo_phy_my_0.083deg_P1M-m` (**monthly**)
  [Subset Form | Copernicus Marine Service](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/download?dataset=cmems_mod_glo_phy_my_0.083deg_P1M-m_202311)
  * Dates: `01/01/1993, 00:00`→`06/01/2021, 00:00`
  * Depths: `0.5 m`→`5727.9 m`

- Dataset: `cmems_mod_glo_phy_myint_0.083deg_P1M-m` (**Interim, monthly**)\
  [Subset Form | Copernicus Marine Service](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/download?dataset=cmems_mod_glo_phy_myint_0.083deg_P1M-m_202311)
  same as above except:
  * Dates: `07/01/2021, 00:00`→`11/01/2024, 00:00`

Variables, keep:

- `thetao`: Sea water potential temperature [°C]
- `bottomT`: Sea water potential temperature at sea floor [°C]
- `so`: Sea water salinity [/ 103]
- `mlotst`: Ocean mixed layer thickness defined by sigma theta [m]

Variables, skip:

- `siconc`: Sea ice area fraction
- `sithick`: Sea ice thickness [m]
- `usi`: Eastward sea ice velocity [m/s]
- `vsi`: Northward sea ice velocity [m/s]
- `uo`: Eastward sea water velocity [m/s]
- `vo`:  Northward sea water velocity [m/s]
- `zos`: Sea surface height above geoid [m]

### Setup dataset parameters

```{r}
#| label: datasets

# py_help(cmt$describe)
# cat_anfc = cmt$describe(
#   contains             = list("GLOBAL_ANALYSISFORECAST_PHY_001_024"), 
#   include_datasets     = T,
#   disable_progress_bar = T)
# cat_rean = cmt$describe(
#   contains             = list("GLOBAL_MULTIYEAR_PHY_001_030", "bottomT"), 
#   include_datasets     = T,
#   disable_progress_bar = T)
# View(cat_rean)

datasets <- list(
  "cmems_mod_glo_phy_my_0.083deg_P1M-m" = list(    # reanalysis monthly
    vars      = list("thetao", "bottomT", "so", "mlotst"),
    date_rng  = c("1993-01-01T00:00:00","2021-06-01T00:00:00"),
    depth_rng =  c(0, 0.5)), # get surface layer only
  "cmems_mod_glo_phy_myint_0.083deg_P1M-m" = list(  # reanalysis monthly, interim
    vars      = list("thetao", "bottomT", "so", "mlotst"),
    date_rng  = c("2021-07-01T00:00:00","2024-12-01T00:00:00"),
    depth_rng =  c(0, 0.5))) # get surface layer only
datasets |> 
  toJSON(auto_unbox = T, pretty=T)
```

### Iterate over sanctuaries & datasets to subset

```{r}
#| label: subset
#| eval: false

for (i in 1:nrow(sanctuaries)){ # i = 1

  d_s <- slice(sanctuaries, i)
  bb <- d_s |> 
    st_buffer(9.25*1000) |> # buffer by a pixel width 1/12° ~ 9.25 km at equator
    st_bbox()

  dir_out <- here(glue("{dir_cm}/{d_s$nms}"))
  dir.create(dir_out, showWarnings=F, recursive=T)
  message(glue("{i}/{nrow(sanctuaries)}: {d_s$sanctuary} ({d_s$nms})"))
  
  for (j in 1:length(datasets)){ # j=1
    
    ds_id <- names(datasets)[j]
    ds    <- datasets[[j]]
    message(glue("{j}/{length(datasets)}: {ds_id}"))
    
    # py_help( cmt$subset)
    nc <- cmt$subset(
      dataset_id            = ds_id,
      # dataset_version     = "202309",
      variables             = ds$vars,
      minimum_longitude     = bb$xmin,
      maximum_longitude     = bb$xmax,
      minimum_latitude      = bb$ymin,
      maximum_latitude      = bb$ymax,
      start_datetime        = ds$date_rng[1],
      end_datetime          = ds$date_rng[2],
      minimum_depth         = ds$depth_rng[1],
      maximum_depth         = ds$depth_rng[2],
      output_directory      = dir_out,
      # force_download        = T,
      # overwrite_output_data = T
      overwrite = T
      # NOTE: should do skip_existing = T for cache?
    )
    nc <- as.character(nc)
    
    # show output_filename with parameters embedded
    # cat(glue("output_filename (basename): {basename(nc)}"))
  }

  # TODO: create .csv-based dir structure to match ERDDAP data outputs
  #       so data can be graphed together.
}
```

:::
